=======================
16S Amplicon Sequencing
=======================

.. important::

    We use DADA2_ pipeline for 16S Amplicon analysis. `DADA2 tutorial`_ provides a good introduction. If using Illumina data with binned quality scores, please checkout `this discussion`_

.. _DADA2: https://doi.org/10.1038/nmeth.3869
.. _DADA2 tutorial: https://benjjneb.github.io/dada2/tutorial.html
.. _this discussion: https://github.com/ErnakovichLab/dada2_ernakovichlab#learn-the-error-rates

    16S amplicon sequencing still remains one of the most widely used methods for the analysis of microbiome community composition. Taxonomic composition, as well as alpha and beta diversity metrics can provide novel biological insight and show association with environmental conditions or clinical variables. 16s rRNA gene is about 1500 bp long and encodes rRNA component of the small subunit of prokaryotic ribosome. The gene is composed of highly conserved and 9 variable regions. This allows us to use the conserved regions as primer binding sites, and variable regions for taxonomic classification.

    .. note:

        Most of 16S sequencing primers (see table below) can only be used for taxonomic classification of prokaryotes. For eukaryotic studies, 18S rRNA sequencing  can be used. Additionally, ITS (Internal Transcribed Spacer), part of the non-transcriptional region of the fungal rRNA gene, can be used for taxonomic classification of fungal species. The ITS sequences used for fungal identification usually include ITS1 and ITS2.


    Although 16S is a cost-effective and powerful technique, a number of factors can influence the outcomes of the analysis, hindering comparisons between studies.
    The outcomes can be influenced by:

    - sampling and sample storage
    - primer annealing efficiency
    - which variable region is targeted
    - library preparation and sequencing protocols
    - bioinformatic processing pipelines (OTUs vs ASVs)
    - database used for taxonomic annotation


16S and 18S Sequencing primers
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Below you can find a table listing commonly used primers for 16S analysis.

As described in `Walters et al`_, 515f-806r bacterial/archaeal primer pair, traditionally used by the `Earth Microbiome Project`_, has been shown to be biased against specific archeal and bacterial clades.  Parada et al. and Apprill et al. have modified the 515f/806r 16S rRNA gene primer pair to reduce these biases.

.. _Walters et al: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5069754/
.. _Earth Microbiom Project: https://earthmicrobiome.org/protocols-and-standards/16s/

=========== =================== ======================== ============= ====== =====================
V-Region    Primer Names        Primer Sequences         Specificity   Size   Reference
V1-V3       27F/534R            | AGAGTTTGATYMTGGCTCAG/  | Bacteria &  507    `Walker et al.`_
                                | ATTACCGCGGCTGCTGG      | Archaea
V3-V4       341F/785R           | CCTACGGGNGGCWGCAG/     | Bacteria &  465     `Klindworth et al.`_
                                | GACTACHVGGGTATCTAATCC  | Archaea
V4          515F/806R           | GTGCCAGCMGCCGCGGTAA/   | Bacteria &  291    `Caporaso et al.`_
                                | GGACTACHVGGGTWTCTAAT   | Archaea
V4          515F-modified/806R  | GTGYCAGCMGCCGCGGTAA/   | Bacteria &  291    `Parada et al.`_
                                | GGACTACHVGGGTWTCTAAT   | Archaea
V4          515F/806R-modified  | GTGCCAGCMGCCGCGGTAA/   | Bacteria &  291    `Apprill et al.`_
                                | GGACTACNVGGGTWTCTAAT   | Archaea
V4-V5       515F/926R           | GTGCCAGCMGCCGCGGTAA/   | Bacteria &  411    `Parada et al.`_
                                | CCGYCAATTYMTTTRAGTTT   | Archaea &
                                                         | Eukaryotes
=========== =================== ======================== ============= ====== =====================

.. _Caporaso et al.: https://doi.org/10.1073/pnas.1000080107
.. _Parada et al.: https://doi.org/10.1111/1462-2920.13023
.. _Apprill et al.: https://doi.org/10.3354/ame01753
.. _Walker et al.: https://doi.org/10.1186/s40168-015-0087-4
.. _Klindworth et al.: https://doi.org/10.1093/nar/gks808


16S Data Analysis
^^^^^^^^^^^^^^^^^

.. mermaid::

   flowchart TD
     subgraph quality [Quality Control]
       direction LR
       id2(1. adapter removal<br/>fa:fa-cog cutadapt) --> id3(2. trim reads <br/>fa:fa-cog dada2)
     end
     subgraph DADA2
       direction LR
       id4(3. learning errors<br/>fa:fa-cog dada2) --> id5(4. sample inference<br/>fa:fa-cog dada2)
       id5 --> id6(5. read merging<br/>fa:fa-cog dada2)
       id6 --> id7(6. chimera removal<br/>fa:fa-cog dada2)
     end
     subgraph tax [Taxonomic Annotation]
     id8(7. assign taxonomy<br/>fa:fa-cog DECIPHER)
     end
     id1(16S Amplicon Analysis) --> quality --> DADA2 --> tax

     classDef tool fill:#96D2E7,stroke:#F8F7F7,stroke-width:1px;
     classDef sub fill:#eeeeee,stroke:#000000
     style id1 fill:#5A729A,stroke:#F8F7F7,stroke-width:1px,color:#fff
     class quality,DADA2,tax sub
     class id2,id3,id4,id5,id6,id7,id8 tool



1. **Removing adapters and splitting reads in forward/reverse orientation**. It is essential to remove adapter sequences for `dada2` pipeline to work properly. For this purpose we use cutadapt_. We run cutadapt_ multiple times to remove adapters that were added to the sequence multiple times. While this happens only rarely, this step saves some work in the downstream analysis. We also split forward and reverse inserts (e.g. 515-926 inserts from 926-515 inserts), as the sequencing protocol produces both orientations.

.. _cutadapt: https://cutadapt.readthedocs.io/en/stable/


2. **Filter and trim the reads**. We next trim low quality bases, this is important for dada2 merging to work. This can be accomplished with DADA2 `filterAndTrim` function.


.. important::
   How much do I truncate?  It is recommended to look at the quality profile of your data, and, while ensuring that you have enough sequence that your forward/reverse reads still overlap enough to merge, truncate off as many of the nucleotides that come after quality crashes as you can. The quality of the reverse reads usually deteriorates faster, thus reverse reads could need more trimming than the forward reads. Leave 30-40 nt overlap for merging.


3. **Learning Error Rates**. DADA2 algorithm needs to first estimate error rates from the data. This should be done separately for samples sequenced on different lanes.

.. warning::

   New Illumina sequencing data (e.g. NovaSeq) provides only binned quality scores (see :doc:`../preprocessing/preprocessing` for more details). This created a problem for dada2 error learning step. This is an ongoing issue, and is discussed in detailed here_ and in `this tutorial`_. Below is our current solution to the problem, the best solution might be dataset specific.

.. _here: https://github.com/benjjneb/dada2/issues/1307
.. _this tutorial: https://github.com/ErnakovichLab/dada2_ernakovichlab#learn-the-error-rates

Here we define a modified error function that maintains monotonicity even with binned quality reads:

.. code-block::

    loessErrfun_mod <- function (trans) {
       qq <- as.numeric(colnames(trans))
       est <- matrix(0, nrow = 0, ncol = length(qq))
       for (nti in c("A", "C", "G", "T")) {
         for (ntj in c("A", "C", "G", "T")) {
           if (nti != ntj) {
             errs <- trans[paste0(nti, "2", ntj), ]
             tot <- colSums(trans[paste0(nti, "2", c("A","C", "G", "T")), ])
             rlogp <- log10((errs + 1)/tot)
             rlogp[is.infinite(rlogp)] <- NA
             df <- data.frame(q = qq, errs = errs, tot = tot,
                           rlogp = rlogp)
             mod.lo <- loess(rlogp ~ q, df, weights = log10(tot),span = 2)
             pred <- predict(mod.lo, qq)
             maxrli <- max(which(!is.na(pred)))
             minrli <- min(which(!is.na(pred)))
             pred[seq_along(pred) > maxrli] <- pred[[maxrli]]
             pred[seq_along(pred) < minrli] <- pred[[minrli]]
             est <- rbind(est, 10^pred)
            } }
            }
       MAX_ERROR_RATE <- 0.25
       MIN_ERROR_RATE <- 1e-07
       est[est > MAX_ERROR_RATE] <- MAX_ERROR_RATE
       est[est < MIN_ERROR_RATE] <- MIN_ERROR_RATE
       err <- rbind(1 - colSums(est[1:3, ]), est[1:3, ], est[4,
                                               ], 1 - colSums(est[4:6, ])
       colSums(est[7:9, ]), est[9, ], est[10:12, ], 1 - colSums(est[10:1
        , est[5:6, ], est[7:8, ], 1 -
        2,
       rownames(err) <- paste0(rep(c("A", "C", "G", "T"), each = 4),
                                  "2", c("A", "C", "G", "T"))
       colnames(err) <- colnames(trans)
       return(err)
        }


The error rates can than be modeled as follows:

.. code-block::

    samplefile <- "samplefile_r1_fw"
    outfile <- "samplefile_r1_fw.errors.rds"
    outfile.plot <- paste(outfile, '.pdf', sep = '')
    threads <- 8
    nbases <- 1e8
    ]))
    sample.files <- read.csv(samplefile, header=FALSE, sep='\t', stringsAsFactors = FA
    LSE)[2]
    s.f <- sample.files$V2
    err <- learnErrors(s.f, nbases=nbases, multithread=threads, randomize=TRUE, verbos
    e = 1, errorEstimationFunction = loessErrfun_mod)
    saveRDS(err, file = outfile)
    plot <- plotErrors(err,nominalQ=TRUE)
    ggsave(outfile.plot, plot = plot)


4. **Sample Inference**. This is the core function of DADA2. Each read, its abundance and its quality is tested if it's an actual, error-free ASV or if it's a spurious sequence with errors. The error function from the previous step is reused. DADA2 is using the error model to infer unique ASVs in each sample. This is also done separately for samples from different lanes. You can read more about the core sample inference algorithm in the `DADA2 paper`_.

.. _DADA2 paper: https://doi.org/10.1038/nmeth.3869

5. **Read Merging**. Now reads can get merged into inserts. The forward subsample is merged in standard orientation. The reverse subsample is merged in inverse orientation. That way, all inserts will have the same orientation after this step.

6. Chimera Removal. Chimeras/Bimeras are removed from each sample individually. Remember that each sample consists of 2 subsamples, forward and reverse:

.. warning::
    Should not be losing a lot of reads in merging and chimera removal.

7. Remove Spurious ASVs. In the next step we merge the individual tables to one big ASV table. Most of the ASVs are spurious and appear in very little counts and in only 1 sample. We remove all ASVs that appear < 5 times.

8. Taxonomic annotation. Taxonomic annotation was performed using IDTAXA_ with the training set corresponding to the SILVA database v.138 and a confidence threshold of 40.

.. _IDTAXA: https://doi.org/10.1186/s40168-018-0521-5